{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/augustopdro/COMPLIANCE-QUALITY-ASSURANCE/blob/main/Checkpoint1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TQF_4a2sp_es",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "40e188df-2eb9-4681-8272-6909dc29bbed"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-579b72917ae6>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Importando os dados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'breast-cancer.data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'breast-cancer.data'"
          ]
        }
      ],
      "source": [
        "# Tratamento dos dados\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Modelos de Machine Learning\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Importando os dados\n",
        "df = pd.read_csv('breast-cancer.data', sep=',', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "__aFe9-7qvWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(7, axis=1)"
      ],
      "metadata": {
        "id": "fDmJkvn9Rr4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "AbTkv6hnR6Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "-KoaDRIbs8XD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "jAUQQBJKwSNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reunindo informações sobre os dados numéricos\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "2zkyS5M1yw_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Checando e confirmando que não há dados nulos na tabela. "
      ],
      "metadata": {
        "id": "FEG8N2G5weNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "MsnHqMSVsGb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={0: \"Class\", 1: \"Age\", 2: \"Menopause\", 3: \"Tumor-size\", 4: \"Inv-nodes\", 5: \"Node-caps\", 6: \"Deg-malig\", 8: \"Breast-quad\", 9: \"Irradiant\"})"
      ],
      "metadata": {
        "id": "R7YxsNexSh9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, age_value in enumerate(df[\"Age\"]):\n",
        "    if \"-\" in age_value:\n",
        "        age_range = age_value.split(\"-\")\n",
        "        age_mean = (int(age_range[0]) + int(age_range[1])) // 2\n",
        "        df.at[i, \"Age\"] = age_mean\n",
        "    else:\n",
        "        df.at[i, \"Age\"] = int(age_value)\n",
        "df[\"Age\"] = pd.to_numeric(df[\"Age\"])"
      ],
      "metadata": {
        "id": "D9xq3BUe5p73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, size_value in enumerate(df[\"Tumor-size\"]):\n",
        "    if \"-\" in size_value:\n",
        "        size_range = size_value.split(\"-\")\n",
        "        size_mean = (int(size_range[0]) + int(size_range[1])) // 2\n",
        "        df.at[i, \"Tumor-size\"] = size_mean\n",
        "    else:\n",
        "        df.at[i, \"Tumor-size\"] = int(size_value)\n",
        "df[\"Tumor-size\"] = pd.to_numeric(df[\"Tumor-size\"])"
      ],
      "metadata": {
        "id": "RhhKsHRE5qpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, nodes_value in enumerate(df[\"Inv-nodes\"]):\n",
        "    if \"-\" in nodes_value:\n",
        "        nodes_range = nodes_value.split(\"-\")\n",
        "        nodes_mean = (int(nodes_range[0]) + int(nodes_range[1])) // 2\n",
        "        df.at[i, \"Inv-nodes\"] = nodes_mean\n",
        "    else:\n",
        "        df.at[i, \"Inv-nodes\"] = int(nodes_value)\n",
        "\n",
        "df[\"Inv-nodes\"] = pd.to_numeric(df[\"Inv-nodes\"])"
      ],
      "metadata": {
        "id": "oHD-81zX8S7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Irradiant'] = df['Irradiant'].replace({'yes': 1, 'no':2})\n",
        "df['Breast-quad'] = df['Breast-quad'].replace({'left_low': 1, 'left_up':2, 'right_low':3, 'right_up':4, 'central': 5, '?':6})\n",
        "df['Node-caps'] = df['Node-caps'].replace({'yes': 1, 'no':2, '?':3})\n",
        "df['Class'] = df['Class'].replace({'no-recurrence-events': 1, 'recurrence-events':2})\n",
        "df['Menopause'] = df['Menopause'].replace({'premeno': 1, 'ge40':2, 'lt40':3})\n",
        "\n",
        "df['Irradiant'].astype(float)\n",
        "df['Breast-quad'].astype(float)      #Transformando-os em números reais\n",
        "df['Node-caps'].astype(float)\n",
        "df['Class'].astype(float)\n",
        "df['Menopause'].astype(float)\n"
      ],
      "metadata": {
        "id": "-3YJicIu7ywS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Node-caps'].unique()"
      ],
      "metadata": {
        "id": "7BzxJxO_9pbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizando as colunas usando o MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "df[[\"Age\", \"Tumor-size\", \"Inv-nodes\"]] = scaler.fit_transform(df[[\"Age\", \"Tumor-size\", \"Inv-nodes\"]])\n",
        "\n",
        "# Padronizando as colunas usando o StandardScaler\n",
        "standard_scaler = StandardScaler()\n",
        "df[[\"Deg-malig\", \"Menopause\", \"Node-caps\", \"Breast-quad\", \"Irradiant\"]] = standard_scaler.fit_transform(df[[\"Deg-malig\", \"Menopause\", \"Node-caps\", \"Breast-quad\", \"Irradiant\"]])"
      ],
      "metadata": {
        "id": "PzGa2mmbW_PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "xffAOXKmXEea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "TnDzUbLPXi-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ajustando outliers do dataset após o tratamento"
      ],
      "metadata": {
        "id": "RqfRnk94Bt1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ajuste_boxplot(data, colunas):\n",
        "  \n",
        "  # Criando uma cópia do DataFrame original\n",
        "  # Dataframes atribuidos com o operador '=' compartilham os index e as informações armazenadas. Para evitar isso usamos o copy()\n",
        "  dados = data.copy()\n",
        "  \n",
        "  for n in range(0, len(colunas)): # Percorrendo a lista das colunas\n",
        "    # Recebendo os dois quartis de interesse\n",
        "    quartis = np.quantile(dados[colunas[n]], [0.25,0.75])\n",
        "\n",
        "    # Calculando os limites superiores e inferiores:\n",
        "    limite_inferior = quartis[0] -1.5*(quartis[1]-quartis[0])\n",
        "    limite_superior = quartis[1] +1.5*(quartis[1]-quartis[0])\n",
        "\n",
        "    # Calculando o valor da mediana\n",
        "    mediana = dados[colunas[n]].median()\n",
        "\n",
        "    # Criando a mascara para filtrar os dados e imprimindo os valores que serão ajustados\n",
        "    mask = (dados[colunas[n]] < limite_inferior) | (dados[colunas[n]] > limite_superior)\n",
        "    print(f\"A coluna {colunas[n]} possui {mask.sum()} outliers para serem tratados\")\n",
        "    \n",
        "    # Substitui os valores pela mediana\n",
        "    dados.loc[mask,colunas[n]] = mediana\n",
        "    \n",
        "    # Exibindo no console a quantidade de valores que foram tratados\n",
        "    mask = (dados[colunas[n]] < limite_inferior) | (dados[colunas[n]] > limite_superior)\n",
        "    print(f\"A coluna {colunas[n]} possui {mask.sum()} outliers após serem tratados\")\n",
        "\n",
        "  return dados"
      ],
      "metadata": {
        "id": "y_pZqxYskRCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colunas_ajuste = list(df.columns)\n",
        "colunas_ajuste"
      ],
      "metadata": {
        "id": "RbgBZt34kQ4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_corr = df.copy()"
      ],
      "metadata": {
        "id": "nf4xOBWakQnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_corr = ajuste_boxplot(df, colunas_ajuste)"
      ],
      "metadata": {
        "id": "EbS4vn1SkXEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.drop(columns = 'Class')\n",
        "y = df['Class']"
      ],
      "metadata": {
        "id": "_i0aoxxqZoza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "fmbLjgiKaaHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NBJf8WfYewV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "redeneural = MLPClassifier(verbose = True, max_iter = 200000, tol = 0.000001, activation = 'relu', #hidden-layer_sizes=(30,30,30), \n",
        "                           learning_rate_init= 0.00001)"
      ],
      "metadata": {
        "id": "1GJD63Ibkbsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "redeneural.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "loPe9EKcknFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "redeneural.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "9K_YaEYhkpjr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}